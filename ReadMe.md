## How to leverage YouTube content in the most efficient way
### Introduction

Content and data are considered as the most significant resources of power in modern digital world. Whosoever controls the data and content has an edge over other competitors in the market. You tube has emerged recently as the highest used video platform for developing the content and leveraging it for expanding one’s reach.

## Installation <a name="installation"></a>

There should be no necessary libraries to run the code here beyond the Anaconda distribution of Python. The code should run with no issues using Python versions 3.*.

### Project Motivation

You tube indeed can be a very effective tool in creating one’s presence among maximum population without expanding much. Analysis of records suggest that PewDiePie-Series and Gaming are the top 3 YouTube channels subscribed most by the audience across the world.

So what is that makes you unique and popular on this widely used platform? Is it like a switch platform where you can just on and off your visibility? Or there are certain strategies and hacks to it that can be utilised to benefit from the systems of the platform. We will be looking at some of the certain ways in which this platform has been leveraged and put to use across the world for maximum productivity and conversions.

There are three main questions I try to find the analysis on
1. The most sought-after contents by the YouTube audience
2. Curating content for segment-specific audience(educational, sports, music)
3. Definitely, Monetising your content.

### Results

The main findings of the code can be found at the [blog post](https://medium.com/@naveenchoudhary_11/how-to-leverage-youtube-in-the-most-efficient-way-410e12be449)

### Licence and Dataset Source

This project is distribute under [MIT](https://opensource.org/licenses/MIT) License.

In this Porject I have analysed Youtube Subscriber data available at kaggle open dataset [here](https://www.kaggle.com/libinmathew264/youtube-top-4000-channels-based-on-subscribers). Dataset ownership and license information can also be found with same link.




